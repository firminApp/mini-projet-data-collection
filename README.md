# ğŸš— Dakar Auto - Scraping & Analytics Application

Application Streamlit pour le scraping et l'analyse des donnÃ©es de [dakar-auto.com](https://www.dakar-auto.com).

## ğŸ“‹ FonctionnalitÃ©s

- **ğŸ” Scraping Interactif**: Scrapez des donnÃ©es sur plusieurs pages avec dÃ©tection automatique du nombre de pages
- **ğŸ“¥ TÃ©lÃ©chargement**: TÃ©lÃ©chargez les donnÃ©es brutes ou nettoyÃ©es au format CSV
- **ğŸ“Š Dashboard**: Visualisations interactives des donnÃ©es nettoyÃ©es (graphiques, statistiques, filtres)
- **ğŸ“ Ã‰valuation**: Formulaire d'Ã©valuation de l'application intÃ©grÃ©

## ğŸ› ï¸ Installation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- pip

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

## ğŸš€ Lancement de l'application

```bash
streamlit run app.py
```

L'application sera accessible Ã  l'adresse: `http://localhost:8501`

## ğŸ“ Structure du projet

```
mini projet/
â”œâ”€â”€ app.py                      # Application principale
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ README.md                   # Documentation
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ scraper.py             # Fonctions de scraping
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scraping.py            # Page de scraping
â”‚   â”œâ”€â”€ download.py            # Page de tÃ©lÃ©chargement
â”‚   â”œâ”€â”€ dashboard.py           # Page du dashboard
â”‚   â””â”€â”€ evaluation.py          # Page d'Ã©valuation
â”œâ”€â”€ data_dakar_auto/           # DonnÃ©es nettoyÃ©es (crÃ©Ã© automatiquement)
â”œâ”€â”€ data_dakar_auto_brutes/    # DonnÃ©es brutes (crÃ©Ã© automatiquement)
â””â”€â”€ evaluations/               # Ã‰valuations sauvegardÃ©es (crÃ©Ã© automatiquement)
```

## ğŸ“Š Sources de donnÃ©es

L'application scrape les donnÃ©es depuis trois catÃ©gories de dakar-auto.com:

1. **ğŸš— Voitures**: https://www.dakar-auto.com/voitures-4
2. **ğŸï¸ Motos**: https://www.dakar-auto.com/motos-and-scooters-3
3. **ğŸš™ Locations**: https://www.dakar-auto.com/location-de-voitures-19

## ğŸ’¡ Utilisation

### 1. Scraping de donnÃ©es

1. AccÃ©dez Ã  la page "ğŸ” Scraping"
2. SÃ©lectionnez la catÃ©gorie (Voitures, Motos, ou Locations)
3. Choisissez le nombre de pages Ã  scraper:
   - DÃ©tection automatique (recommandÃ©)
   - Nombre manuel de pages
4. Option: Activer le nettoyage des donnÃ©es
5. Cliquez sur "ğŸš€ Lancer le scraping"
6. TÃ©lÃ©chargez ou sauvegardez les rÃ©sultats

### 2. TÃ©lÃ©chargement de donnÃ©es

1. AccÃ©dez Ã  la page "ğŸ“¥ TÃ©lÃ©chargement"
2. Choisissez entre donnÃ©es brutes ou nettoyÃ©es
3. Visualisez les fichiers disponibles
4. TÃ©lÃ©chargez individuellement ou en lot (ZIP)

### 3. Visualisation des donnÃ©es

1. AccÃ©dez Ã  la page "ğŸ“Š Dashboard"
2. SÃ©lectionnez un fichier de donnÃ©es nettoyÃ©es
3. Explorez les visualisations:
   - Statistiques globales
   - Graphiques interactifs
   - Tableaux filtrables

### 4. Ã‰valuation de l'application

1. AccÃ©dez Ã  la page "ğŸ“ Ã‰valuation"
2. Remplissez le formulaire intÃ©grÃ© ou Google Forms
3. Soumettez votre Ã©valuation

## ğŸ”§ Configuration

### Personnalisation du scraping

Modifiez `utils/scraper.py` pour:
- Ajuster les dÃ©lais entre les requÃªtes
- Modifier les sÃ©lecteurs HTML
- Ajouter de nouvelles fonctions de nettoyage

### Personnalisation du dashboard

Modifiez `pages/dashboard.py` pour:
- Ajouter de nouveaux graphiques
- Modifier les couleurs et thÃ¨mes
- CrÃ©er des analyses personnalisÃ©es

## ğŸ“¦ DÃ©ploiement

### Streamlit Cloud

1. CrÃ©ez un compte sur [Streamlit Cloud](https://streamlit.io/cloud)
2. Connectez votre repository GitHub
3. DÃ©ployez l'application en un clic

### Autres options

- **Heroku**: Utilisez un `Procfile` avec `web: streamlit run app.py`
- **Docker**: CrÃ©ez un Dockerfile basÃ© sur `python:3.9-slim`
- **AWS/GCP/Azure**: DÃ©ployez sur une instance avec Streamlit installÃ©

## âš ï¸ Avertissements

- **Respect du site web**: Utilisez des dÃ©lais raisonnables entre les requÃªtes
- **DonnÃ©es personnelles**: Ne partagez pas les donnÃ©es scrapÃ©es publiquement
- **LÃ©galitÃ©**: VÃ©rifiez les conditions d'utilisation du site avant de scraper
- **Performance**: Le scraping de toutes les pages peut prendre du temps

## ğŸ“ Notes techniques

### DonnÃ©es brutes vs nettoyÃ©es

- **DonnÃ©es brutes**: Valeurs extraites telles quelles du site (avec espaces, symboles, etc.)
- **DonnÃ©es nettoyÃ©es**: Valeurs formatÃ©es avec colonnes numÃ©riques additionnelles (prix_numerique, km_numerique, etc.)

### Rate limiting

L'application attend 1 seconde entre chaque requÃªte de page pour Ã©viter de surcharger le serveur.

## ğŸ¤ Contribution

Pour contribuer au projet:

1. Fork le repository
2. CrÃ©ez une branche pour votre fonctionnalitÃ©
3. Committez vos changements
4. Poussez vers la branche
5. CrÃ©ez une Pull Request

## ğŸ“„ Licence

Ce projet est Ã  usage Ã©ducatif uniquement.

## ğŸ‘¥ Auteurs

- Projet dÃ©veloppÃ© dans le cadre du Master IA - DIT
- Module: Data Collection

## ğŸ“ Support

Pour toute question ou problÃ¨me:
- Ouvrez une issue sur GitHub
- Contactez l'Ã©quipe de dÃ©veloppement
- Consultez la documentation Streamlit: https://docs.streamlit.io

## ğŸ¯ Roadmap

FonctionnalitÃ©s futures prÃ©vues:
- [ ] Export Excel en plus du CSV
- [ ] Filtres avancÃ©s dans le dashboard
- [ ] API REST pour accÃ©der aux donnÃ©es
- [ ] Notifications par email aprÃ¨s scraping
- [ ] Planification automatique du scraping
- [ ] Support multilingue (FranÃ§ais/Anglais)
- [ ] Mode sombre/clair
- [ ] Comparaison entre pÃ©riodes diffÃ©rentes

## ğŸ™ Remerciements

- [Streamlit](https://streamlit.io) pour le framework
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) pour le parsing HTML
- [Plotly](https://plotly.com) pour les visualisations
- [dakar-auto.com](https://www.dakar-auto.com) pour les donnÃ©es

---

**Made with â¤ï¸ and Python**
